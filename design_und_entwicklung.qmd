# Design und Entwicklung

## Datenbeschaffung

Zur Beschaffung der Daten, legten wir erst fest, welche Daten für uns und das LLM sinvoll sind. Um die Daten auch öfter zu sammeln, da Festool in der Zeit der Entwicklung neue Produkte oder Preise ändern könnte, haben wir diesen Prozess automatisiert. \
Dazu programmierten wir einen Webscraper der dies für alle Produkte auf der Festool Website erledigt und uns die Daten in einer Textdatei speichert.
Folgende Daten wurden gespeichert: 

- URL
- Name
- Artikelnummer
- Bruttopreis
- Beschreibung (Produktbeschreibung)
- Vorteile / Benefits
- Technische Daten
- Highlights

Programmiert wurde der Webscraper mittels Python. 

**Funktionsweise:**

Der Webscraper besucht die Festtool Website und akzeptiert die Cookies. Danach wird für jede Prouktkategorie folgendes ausgeführt. /
Das Programm speichert jede URL eines Prdukts ab, welches sich in der jeweiligen Produktkategorie befindet. \
Im Laufe des Programms besucht der Scraper dann jede URL und speichert die oben genannten Features ab. /
Findet er die Daten nicht, lässt er das Feld frei und geht zum nächsten. Dieser Fall ist allerding selten. 

Aufgrund der Automatisierung können wir nun schnell alle für uns relevanten Produkinformationen aus dem Webshop laden.

***Link zum GitHub Repository: *** [https://github.com/llm-hdm/page-scraper](https://github.com/llm-hdm/page-scraper)

## Prompt Engineering

Prompt Engineering ist eine Methode, die die Leistung von Large Language Models (LLMs) verbessert, indem sie gezielt formulierte Eingabeanweisungen, sogenannte "Prompts", verwendet. Diese Anweisungen dienen dazu, die Ausgabe des Modells zu lenken und präziser auf spezifische Aufgaben oder Kontexte zuzuschneiden.

Die Grundidee hinter Prompt Engineering besteht darin, dem LLM klare und präzise Anweisungen zu geben, wie es die gestellte Aufgabe verstehen und bearbeiten soll. Diese Prompts können in Form von Beispielsätzen, Fragen oder Anweisungen formuliert werden, um dem Modell Kontext und Richtung zu geben. Durch das Feintuning dieser Prompts kann die Leistung des LLMs verbessert werden, indem es genauer und zielgerichteter reagiert.

Ein Beispiel wäre die Verwendung eines LLMs zur Textgenerierung. Ein Forscher, der die Qualität der Erklärungen des Modells verbessern möchte, könnte ein spezifisches Prompt verwenden, das dem Modell klare Anweisungen gibt, um detaillierte und verständliche Antworten zu generieren. Ein solches Prompt könnte lauten: "Erkläre präzise und verständlich den Prozess der Photosynthese in Pflanzen." Durch die präzise Formulierung des Prompts wird das Modell darauf trainiert, genau auf diese Anforderungen zu reagieren und genaue Erklärungen zu liefern. So kann Prompt Engineering die Ausgabequalität und Relevanz des Modells in bestimmten Anwendungsfällen deutlich verbessern.


## Evaluation of the Model

tbd

## Software Architecture

Aufgrund der schnellen Entwicklung von technologien im Bereich von LLM's haben wir in der Zeit der Entwicklung zwei verschiedene Software Architekturen implementiert. \
Zu Beginn basierte unser Protoyp auf GPT3.5 turbo. Im Laufe der Entwicklung haben wir das Modell auf GPT4.5 turbo umgestellt. Dies hatte deutliche performance verbesserungen. Gleichzeitig konnten wir die genauigkeit des Modells verbessern. Zudem hat das neue Modell uns den Vorteil geboten, mehr Tokens pro Request an das Modell mitzugeben. \
Die Vektor-Datenbank (ChromaDB) haben wir durch OpenAI's eigenen Assistent abgelöst. Auch hier konnten wir eine deutliche verbesserung der performance als auch der genauigkeit des Outputs des Modells erhalten.

**Version 1:**

<img src="images/Software_Architektur_1.png" width="650">

**Version 2:**

<img src="images/Software_Architektur_2.png" width="650">

## User Interface (UI) Design

Für das Design des User Interface orientierten wir uns an dem Coperate Design von Festool. Uns war es wichtig, dass wir ein Produkt entwickeln dass jederzeit auf dem Webshop, bzw. der Website von Festool eingebunden werden könnte. \
So haben wir uns dazu entschieden einen Button zu bauen, der OnClick ein Chatfenster öffnet. Wir haben besonders darauf geachtet, dass das Chatfenster, wie z.B. von anderen Messengern, vom User intuitiv und gewohnt benutzt werden kann. \
Zudem steht es dem User frei, einen Darkmode oder den normalen weißen Modus des Chatbots zu verwenden.

**Dark-Mode:**

![](images/Darkmode1.png){width=50%} 

**Normal-Mode:**

![](images/Darkmode2.png){width=50%}

## Frontend

/////////// 

## Backend

//////////